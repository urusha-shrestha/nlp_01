{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4842e317",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1732807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1068d4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/final_cleaned.csv', usecols=['cleaned_text', 'sentiment'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "577bb255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sixteen year old border collie love food shes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bought pb pb chocolateand completely wonderful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>boyfriend love pancake always think different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>mix three tablespoon morning smoothie protein ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>family love taco night dont make often enough ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                       cleaned_text\n",
       "0          1  sixteen year old border collie love food shes ...\n",
       "1          1  bought pb pb chocolateand completely wonderful...\n",
       "2          1  boyfriend love pancake always think different ...\n",
       "3          1  mix three tablespoon morning smoothie protein ...\n",
       "4          1  family love taco night dont make often enough ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662318b",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b49c7737",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform(df['cleaned_text'])\n",
    "# temp_df = pd.DataFrame(bow.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "# df_bow = pd.concat([df, temp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7afd298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 59947)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae7a0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaah', 'aadmit', 'aadp', 'aafco', 'aafes',\n",
       "       'aakaufmanerthlinknet', 'aamazoni', 'aap', 'aarthur', 'aaworld',\n",
       "       'ab', 'aback', 'abalone', 'abandon', 'abandoned', 'abandoning',\n",
       "       'abated', 'abbaye', 'abbazabba', 'abbey', 'abbott', 'abbreviated',\n",
       "       'abbreviating', 'abby', 'abc', 'abcstores', 'abctoyme', 'abd',\n",
       "       'abdomen', 'abdominal', 'aber', 'aberdeen', 'aberrant',\n",
       "       'aberration', 'abet', 'abetter', 'abfab', 'abhor', 'abhorrent',\n",
       "       'abi', 'abide', 'abides', 'abietate', 'abigirl', 'ability', 'abit',\n",
       "       'abject', 'ablation', 'able', 'abletate', 'ablution', 'abnormal',\n",
       "       'abnormality', 'abnormally', 'abnoxious', 'aboard', 'abominably',\n",
       "       'abomination', 'aboout', 'aborted', 'aboslutely', 'abosolutely',\n",
       "       'abottle', 'abotu', 'abouit', 'abound', 'abounds', 'abour',\n",
       "       'aboutcom', 'aboutcomes', 'aboutembarrassing', 'abouti',\n",
       "       'aboutlaurie', 'aboutnow', 'aboveaverage', 'abovedescribed',\n",
       "       'abra', 'abrasion', 'abreast', 'abroad', 'abrotanum', 'abrubt',\n",
       "       'abrubtly', 'abruptly', 'absconded', 'absconding', 'absence',\n",
       "       'absense', 'absent', 'absente', 'absentmindedly', 'absentmindly',\n",
       "       'absfave', 'absinthe', 'absintheloving', 'absinthium', 'absoltely',\n",
       "       'absoluely', 'absoluey', 'absolut', 'absolute', 'absolutedly',\n",
       "       'absolutely', 'absolutey', 'absolutlely', 'absolutley',\n",
       "       'absolutly', 'absorb', 'absorbable', 'absorbant', 'absorbe',\n",
       "       'absorbed', 'absorbency', 'absorbent', 'absorber', 'absorbes',\n",
       "       'absorbing', 'absorbs', 'absorbtion', 'absorption', 'absortion',\n",
       "       'absoulutely', 'absoute', 'absoutely', 'abstain', 'abstaining',\n",
       "       'abstinence', 'abstract', 'abstraction', 'absurd', 'absurdity',\n",
       "       'absurdly', 'abt', 'abundance', 'abundant', 'abundence', 'abuse',\n",
       "       'abused', 'abusing', 'abusive', 'abut', 'abv', 'abysmal',\n",
       "       'abysmally', 'abyssinian', 'ac', 'acacia', 'academy', 'acai',\n",
       "       'acaiacute', 'acaigreen', 'acaipomegranate', 'acana', 'accelerade',\n",
       "       'accelerate', 'accelerates', 'accelerating', 'accent', 'accented',\n",
       "       'accentspretty', 'accentuate', 'accentuated', 'accentuates',\n",
       "       'accentuating', 'accept', 'acceptability', 'acceptable',\n",
       "       'acceptablelight', 'acceptably', 'acceptalble', 'acceptale',\n",
       "       'acceptance', 'accepted', 'accepting', 'accepts', 'acces',\n",
       "       'accesories', 'accesory', 'access', 'accessability', 'accessable',\n",
       "       'accessed', 'accessible', 'accessing', 'accessory', 'accident',\n",
       "       'accidentagain', 'accidental', 'accidentally', 'accidently',\n",
       "       'accidentswe', 'accidic', 'acclaim', 'acclaimed', 'acclimate',\n",
       "       'acclimated', 'accolade', 'accommodate', 'accommodated'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73887948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
